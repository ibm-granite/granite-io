interactions:
- request:
    body: '{"model":"granite3.2:2b","prompt":"<|start_of_role|>system<|end_of_role|>Knowledge
      Cutoff Date: April 2024.\nToday''s Date: March 04, 2025.\nYou are Granite, developed
      by IBM. You are a helpful AI assistant.<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>Hello,
      how are you?<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>I''m doing
      great. How can I help you today?<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>I''d
      like to show off how chat templating works!<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>","best_of":1,"n":1}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '556'
      content-type:
      - application/json
      host:
      - localhost:11434
      rits_api_key:
      - ollama
      user-agent:
      - OpenAI/Python 1.65.3
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.65.3
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.6
    method: POST
    uri: http://localhost:11434/v1/completions
  response:
    body:
      string: "{\"id\":\"cmpl-381\",\"object\":\"text_completion\",\"created\":1741134279,\"model\":\"granite3.2:2b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"text\":\"That
        sounds interesting! Chat templates allow users and developers to create dynamic
        responses in conversations by embedding variables, which can then be filled
        with specific data on the fly. Here's a simple example of how it might work:\\n\\nSay
        we've created a chat template for ordering food called \\\"Order Pizza\\\"
        \u2013 here\u2019s how it could look:\\n\\n```\\nHello customer! You're about
        to order a pizza. Please tell me:\\n1. **Pizza Base:** [Available options
        like 'Thin Crust', 'Deep Dish']\\n2. **Sauce Topping(s):** [Choose from available
        options such as 'Tomato', 'Barbecue', etc.]\\n3. **Cheese Toppings:** [Options
        are often 'Mozzarella', 'Cheddar', etc.]\\n4. **Extra Toppings (choose any
        or none)?** \\n\\nPlease enter your choices:\\n\\n**Pizza Base:** _{{Pizza
        Base}}$\\n**Sauce Topping(s):** _{{Sauces}}_ (enter comma-separated)\\n**Cheese
        Toppings:** _{{Cheeses}}_ (enter each topping separately)\\n**Extra Toppings:**
        ${{extras}}$ (leave blank if no extras)\\n```\\n\\nWhen a user inputs their
        preferences through this template, the chatbot will process it as follows:\\n\\nIf
        the user says, \\\"I want thin crust, barbecue sauce, mozzarella cheese, and
        bacon for extra toppings,\\\" our bot could generate this response:\\n\\n\\\"Great
        choices! Your order is ready. Here's your pizza:\\n- Base: Thin Crust\\n-
        Sauce Topping(s): Barbecue\\n- Cheese Toppings: Mozzarella\\n- Extra Toppings:
        Bacon\\\"\\n\\nHere the placeholders (`{{...}}`) will be replaced with actual
        user input, making each response personalized and accurate based on their
        preferences. This is the power of chat templates \u2013 they give conversations
        a fluid, dynamic nature by easily adapting answers to diverse inputs while
        maintaining clarity and relevance.\",\"index\":0,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":142,\"completion_tokens\":457,\"total_tokens\":599}}\n"
    headers:
      Content-Length:
      - '1961'
      Content-Type:
      - application/json
      Date:
      - Wed, 05 Mar 2025 00:24:39 GMT
    status:
      code: 200
      message: OK
version: 1
